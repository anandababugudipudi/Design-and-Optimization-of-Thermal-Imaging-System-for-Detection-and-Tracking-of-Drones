{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JtJC2aqWpxOQ"
   },
   "source": [
    "## **Import the necessary packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hb-WfnGQpsVk"
   },
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uIfrsfX0WX2-",
    "outputId": "ff043578-b5cb-4ebb-b3c1-3b06b028fc7a"
   },
   "outputs": [],
   "source": [
    "# Checking the colab env\n",
    "import tensorflow as tf\n",
    "print(tf.test.gpu_device_name())\n",
    "from tensorflow.python.client import device_lib\n",
    "print(\"List of GPUs:\", device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "risnDcCtBwJV"
   },
   "source": [
    "##**Download the Dataset**\n",
    "\n",
    "Just for initial experiments download the dataset into colab workspace and extract here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mm6e4RNNpaLv"
   },
   "outputs": [],
   "source": [
    "# Download the dataset or link dataset from GDrive\n",
    "def download_external_dataset():\n",
    "  if (os.path.isfile(\"Mini_Dataset.zip\")):\n",
    "    print(\"Dataset is already downloaded in workspace. Continuing with that...\")\n",
    "  else:\n",
    "    !wget <LINK TO FILE>\n",
    "    !unzip <ZIP FILE NAME> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_ryG_6cYQ1o"
   },
   "source": [
    "## **Connecting to Google Drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LQyUZx80AY-U",
    "outputId": "0f7afe84-a3d8-4c32-cb7f-022ae016a424"
   },
   "outputs": [],
   "source": [
    "# Connect to GDrive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r7JZcs969UL9"
   },
   "outputs": [],
   "source": [
    "# Set the project path to \"PATH\" \n",
    "PATH = \"<PROJECT FOLDER PATH>\"\n",
    "# Set the dataset path to \"DATASET_PATH\"\n",
    "DATASET_PATH = \"<DATASET FOLDER PATH>\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jqcZxMT_9cVf",
    "outputId": "6638fa07-3e4f-4633-a6fa-f12faf123b8d"
   },
   "outputs": [],
   "source": [
    "%cd $PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTWCpN8tKILq"
   },
   "source": [
    "## **Downloading and Configuring the Darknet**\n",
    "\n",
    "Run this section for first time only. In later executions you can skip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "id": "BLTjLqxUCaNo",
    "outputId": "1fcb9981-12d7-40dd-ccd4-6f2bcbc75bb3"
   },
   "outputs": [],
   "source": [
    "# Create a new folder for downloading Darknet\n",
    "os.mkdir(\"Darknet\")\n",
    "!git clone 'https://github.com/AlexeyAB/darknet.git' os.path.join($PATH, \"Darknet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7eawXNlAC_0B",
    "outputId": "81d0fc02-5502-405e-cfde-c087392ae9aa"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWB4bINMDQqQ"
   },
   "source": [
    "Edit the \"Makefile\" and change the variables \"GPU, CUDNN, OPENCV\" to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c94_ISsySXDh",
    "outputId": "847c9856-87e8-4613-e564-0538db2eb46d"
   },
   "outputs": [],
   "source": [
    "# Define variables for paths of darknet and makefile\n",
    "darknet_path = PATH + \"/Darknet\"\n",
    "makefile_path = darknet_path + \"/Makefile\"\n",
    "# Change the variables \"GPU, CUDNN, OPENCV\" to 1\n",
    "with open(makefile_path, \"r+\") as makefile:\n",
    "  makefile_contents = makefile.read()\n",
    "  makefile_contents = re.sub(\"GPU=0\", \"GPU=1\", makefile_contents)\n",
    "  makefile_contents = re.sub(\"CUDNN=0\", \"CUDNN=1\", makefile_contents)\n",
    "  makefile_contents = re.sub(\"OPENCV=0\", \"OPENCV=1\", makefile_contents)\n",
    "  makefile.seek(0)\n",
    "  makefile.write(makefile_contents)\n",
    "  makefile.truncate()\n",
    "  print(\"The variables 'GPU, CUDNN, OPENCV' are changed to 1.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XWgoCDdPDE5Q"
   },
   "outputs": [],
   "source": [
    "# Change the directory to darknet\n",
    "%cd $darknet_path\n",
    "# Run the Makefile using 'make' command\n",
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h1nCwrD5mi9W",
    "outputId": "2f6d09cf-c72e-42ad-950f-ebf9a65a4f30"
   },
   "outputs": [],
   "source": [
    "# Check if darknet is properly installed or not\n",
    "!./darknet\n",
    "%cd $PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPGoZat1EJIP"
   },
   "source": [
    "## **Create Training and Testing Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nlB0GkCwESPz"
   },
   "source": [
    "###**Create files data and names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_DvtHEGXGFap"
   },
   "outputs": [],
   "source": [
    "# Method to create files data and class names\n",
    "def create_files_data_and_names(dataset_path):\n",
    "  \"\"\" Create classes.names \"\"\"  \n",
    "  # Counter for number of classes\n",
    "  classes = 0\n",
    "  # Creating file classes.names from existing classes.txt\n",
    "  print(\"The following are the classes in out Dataset:\\n\")\n",
    "  with open(dataset_path + '/' + 'classes.names', 'w') as names, open(dataset_path + '/' + 'classes.txt', 'r') as txt:\n",
    "    for line in txt:\n",
    "      names.write(line)\n",
    "      print(line)\n",
    "      classes += 1\n",
    "\n",
    "  \"\"\" Create file labelled_data.data \"\"\"\n",
    "  with open(dataset_path + '/' + 'labelled_data.data', 'w') as data:\n",
    "    print(\"\\nThe file 'labelled_data.data' is saved in the following location:\\n\")\n",
    "    print(os.path.join(dataset_path, \"labelled_data.data\"))\n",
    "    data.write(f\"classes = {classes} \\n\")\n",
    "    # Location of the train.txt file\n",
    "    data.write(f\"train = {dataset_path}/train.txt\\n\")\n",
    "    # Location of the test.txt file\n",
    "    data.write(f\"valid = {dataset_path}/test.txt\\n\")\n",
    "    # Location of the classes.names file\n",
    "    data.write(f\"names = {dataset_path}/classes.names\\n\")\n",
    "    # Location where to save weights\n",
    "    data.write('backup = backup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SUezCY_nJpqf",
    "outputId": "7f1c0c6a-734f-42b6-de6e-a1ddf02b362b"
   },
   "outputs": [],
   "source": [
    "# Creating the files data and names\n",
    "create_files_data_and_names(DATASET_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ybwk6ZT53H0i"
   },
   "source": [
    "###**Creating Train and Test txt files**\n",
    "Now we have to create the Train and Test data with split of 70:30 ratio. It will create Train.txt with 70% of the files paths and Test.txt with 30% of the file paths. 30% test size is given by default. We can change it if we want to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6a5figCW3SFl"
   },
   "outputs": [],
   "source": [
    "def create_train_test_txt_files(dataset_path, test_size = 0.3):\n",
    "  # Defining list to write paths in\n",
    "  p = [dataset_path + \"/\" + file + \"\\n\" for file in os.listdir(dataset_path) if (os.path.splitext(file)[1] == \".jpg\")]\n",
    "\n",
    "  # Slicing first test_size % of elements from the list to write into the test.txt file\n",
    "  p_test = p[:int(len(p) * test_size)]\n",
    "  # Deleting from initial list first test_size % of elements\n",
    "  p = p[int(len(p) * test_size):]\n",
    "\n",
    "  # Creating file train.txt and writing 85% of lines in it\n",
    "  with open(dataset_path + '/train.txt', 'w') as train_txt:\n",
    "      # Going through all elements of the list\n",
    "      for e in p:\n",
    "          # Writing current path at the end of the file\n",
    "          train_txt.write(e)\n",
    "\n",
    "  # Creating file test.txt and writing 15% of lines in it\n",
    "  with open(dataset_path + '/test.txt', 'w') as test_txt:\n",
    "      # Going through all elements of the list\n",
    "      for e in p_test:\n",
    "          # Writing current path at the end of the file\n",
    "          test_txt.write(e)\n",
    "\n",
    "  print(f\"Train set files: {len(p)}\")\n",
    "  print(f\"Test set files: {len(p_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xxjEjEWg4FR8",
    "outputId": "3ea287fd-10ac-4e73-94ab-ca7a2298a732"
   },
   "outputs": [],
   "source": [
    "# Creating the train and test txt files\n",
    "create_train_test_txt_files(DATASET_PATH, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lANtEA6aRXW0",
    "outputId": "2c70c3eb-edc5-4b12-d05e-a5d699ba7f5e"
   },
   "outputs": [],
   "source": [
    " with open(DATASET_PATH + '/test.txt', 'r') as test_txt:\n",
    "   lines = test_txt.readlines()\n",
    "print(lines[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0JkHPAfofk_",
    "outputId": "32546b9c-8944-4e18-9c19-f17590cdff7b"
   },
   "outputs": [],
   "source": [
    "len(os.listdir(DATASET_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "miEz4-Z8AXjt"
   },
   "source": [
    "Now create a folder 'Custom_Weights' in Project Folder. From here onwards we need to apply Transfer Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i2BZhKNPAgAk"
   },
   "outputs": [],
   "source": [
    "# Create 'Custom_Weights' and 'backup' folders\n",
    "os.mkdir(\"Custom_Weights\")\n",
    "os.mkdir(\"backup\")\n",
    "print(\"'Custom_Weights' and 'backup' folders are created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ktIDZ5w6AjjD",
    "outputId": "699041c9-b285-4456-918f-4429e475d579"
   },
   "outputs": [],
   "source": [
    "%cd \"Custom_Weights\"\n",
    "# Download pre-trained DArknet weights\n",
    "!wget https://pjreddie.com/media/files/darknet53.conv.74\n",
    "%cd $PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "id": "gqBoqZzlQvSv",
    "outputId": "7e09b0b3-e884-45f5-f3b5-2199f5437de7"
   },
   "outputs": [],
   "source": [
    "os.remove(\"Darknet/cfg/yolov3.cfg\")\n",
    "!unzip yolov3.zip\n",
    "shutil.move('yolov3.cfg', \"Darknet/cfg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmIHDw04CeQB"
   },
   "source": [
    "###**Configuring the 'yolov3.cfg' file.**\n",
    "1. Goto Darknet Folder and under cfg folder we can find yolov3.cfg file\n",
    "2. Open this file and change the following things.\n",
    "    For Training:\n",
    "        Uncomment the 3 lines (5, 6 ,7) and give the batch_size and subdivisions\n",
    "    For Testing\n",
    "        Uncomment the 3 lines (2, 3, 4) and give the batch_size and subdivisions\n",
    "    We can change the 'maxbatches' in line 20 to (number of classes * 2000)\n",
    "    We can change the 'steps' (min steps, max steps)\n",
    "3. Now go to the last 3 YOLO Layers and change these yolo layers and preceding conv layers only.\n",
    "    In first layer\n",
    "        At line 603, change number of filters to (num of classes + 5) * 3\n",
    "        At line 610, change number of classes to our num of classes\n",
    "    Do the same thing for next 2 layers\n",
    "        At line 689, 696 and 776, 783.\n",
    "4. Save the file "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqQZqrL8GW-_"
   },
   "source": [
    "##**Start Training the Model**\n",
    "Train the model with the given format\n",
    "\n",
    "     !darknet/darknet detector train <labelled_data.data file path> <yolov3.cfg file path> <Custom Weights path> -gpus 0 -dont_show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HQzod3EWIfrf",
    "outputId": "9df56418-f689-4de0-bcd3-d5fd75ec1a89"
   },
   "outputs": [],
   "source": [
    "# Training the Model\n",
    "!./Darknet/darknet detector train \"Mini_Dataset/labelled_data.data\" \"Darknet/cfg/yolov3.cfg\" \"Custom_Weights/darknet53.conv.74\" -gpus 0 -dont_show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtfykbOkcFSw"
   },
   "source": [
    "##**Testing the Model**\n",
    "Test the model with the given format on image\n",
    "\n",
    "      !darknet/darknet detector test <labelled_data.data file path> <yolov3.cfg file path> <Trained Weights path> -thresh <Image Path>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lvvCxQcNcJNt"
   },
   "outputs": [],
   "source": [
    "# Test the Model on image\n",
    "!./Darknet/darknet detector test \"./Dataset/labelled_data.data\" \"./Darknet/cfg/yolov3.cfg\" \"./backup/yolov3_last.weights\" -thresh 0.20 \"Image Path\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xlqk-n4iGF7"
   },
   "source": [
    "##**Testing the Model on Video**\n",
    "Test the model with the given format on Video\n",
    "\n",
    "      !darknet/darknet detector demo <labelled_data.data file path> <yolov3.cfg file path> <Trained Weights path> -thresh 0.20 -dont_show <Input Video Path> -out_filename <Output Video Path>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cKd52d7niEWO"
   },
   "outputs": [],
   "source": [
    "# Test the Model on Video\n",
    "!./Darknet/darknet detector demo \"./Mini_Dataset/labelled_data.data\" \"./Darknet/cfg/yolov3.cfg\" \"./backup/yolov3_last.weights\" -thresh 0.20 \"./Video_IR/IR_AIRPLANE_001.mp4\" -out_filename \"./Video_IR/IR_AIRPLANE_001_out.mp4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VtC4y-e5NJkh"
   },
   "outputs": [],
   "source": [
    "# Resetting the environment for re-run\n",
    "def reset_env():\n",
    "  os.remove(DATASET_PATH + \"/labelled_data.data\")\n",
    "  os.remove(DATASET_PATH + \"/classes.names\")\n",
    "  os.remove(DATASET_PATH + \"/train.txt\")\n",
    "  os.remove(DATASET_PATH + \"/test.txt\")\n",
    "  os.rmdir(PATH + \"/backup\")\n",
    "  os.rmdir(PATH +\"/Custom_Weights\")\n",
    "  os.rmdir(PATH + \"Darknet\")\n",
    "  print(\"Environment reset successfully\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Drone Detection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
